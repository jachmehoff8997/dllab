{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNH7DCt6y1kMUj4F9JkgTqo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jachmehoff8997/dllab/blob/main/DLlab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.Learning rules"
      ],
      "metadata": {
        "id": "htx6co5JMrMQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "s6PMeRNUIr21",
        "outputId": "41f8f652-f6e8-423c-a43f-7fe649fa55fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  100k  100  100k    0     0  1044k      0 --:--:-- --:--:-- --:--:-- 1053k\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "OpenCV(4.8.0) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-56d296d70ccd>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Load content and style images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mcontent_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'content.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mstyle_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'style.jpeg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Load the TensorFlow Hub model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-56d296d70ccd>\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.8.0) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "!curl https://imgur.com/9ooB60I.jpeg -o style.jpeg\n",
        "!curl https://i.imgur.com/F28w3Ac.jpg -o content.jpg\n",
        "\n",
        "# Load the images\n",
        "def load_img(path):\n",
        "    img = cv2.imread(path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = img / 255.0\n",
        "    return img\n",
        "\n",
        "# Load content and style images\n",
        "content_image = load_img('content.jpg')\n",
        "style_image = load_img('style.jpeg')\n",
        "\n",
        "# Load the TensorFlow Hub model\n",
        "model = hub.load('https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/2')\n",
        "\n",
        "# Apply the style transfer\n",
        "def apply_style(content_image, style_image):\n",
        "    content_image = content_image[np.newaxis, ...].astype('float32')\n",
        "    content_image = tf.convert_to_tensor(content_image)\n",
        "\n",
        "    style_image = cv2.resize(style_image, (256, 256))\n",
        "    style_image = style_image[np.newaxis, ...].astype('float32')\n",
        "    style_image = tf.convert_to_tensor(style_image)\n",
        "\n",
        "    outputs = model(tf.constant(content_image), tf.constant(style_image))\n",
        "    stylized_image = outputs[0]\n",
        "    return stylized_image\n",
        "\n",
        "# Display the stylized image\n",
        "stylized_img = apply_style(content_image, style_image)\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.grid(False)\n",
        "plt.imshow(stylized_img[0])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.Perceptrons"
      ],
      "metadata": {
        "id": "En-JU2xgMpcg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class Perceptron:\n",
        "    \"\"\"\n",
        "    A simple perceptron classifier.\n",
        "    \"\"\"\n",
        "    def __init__(self, weights=None, bias=0):\n",
        "        self.weights = weights\n",
        "        self.bias = bias\n",
        "\n",
        "    def initialize(self, n_features):\n",
        "        \"\"\"\n",
        "        Set initial weights and bias to zeros if not provided.\n",
        "        \"\"\"\n",
        "        if self.weights is None:\n",
        "            self.weights = np.zeros(n_features)\n",
        "        if self.bias is None:\n",
        "            self.bias = 0\n",
        "\n",
        "    def predict(self, inputs):\n",
        "        \"\"\"\n",
        "        Predict the class labels for new input data.\n",
        "        Calculate the step activation function.\n",
        "        \"\"\"\n",
        "        activation = np.dot(inputs, self.weights) + self.bias\n",
        "        return 1 if activation > 0 else 0\n",
        "\n",
        "    def train(self, X, y, epochs=100, learning_rate=0.1):\n",
        "        \"\"\"\n",
        "        Train the perceptron using the input data and target labels.\n",
        "        \"\"\"\n",
        "        # Initialize the weights and bias\n",
        "        self.initialize(X.shape[1])\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            for inputs, label in zip(X, y):\n",
        "                # Get prediction\n",
        "                y_pred = self.predict(inputs)\n",
        "                # Calculate delta error\n",
        "                error = label - y_pred\n",
        "                # Update weights and bias\n",
        "                self.weights += learning_rate * error * inputs\n",
        "                self.bias += learning_rate * error\n",
        "\n",
        "# Example usage with customized weights\n",
        "X_train = np.array([[0, 0, 1], [0, 1, 1], [1, 0, 1], [1, 1, 1]])\n",
        "y_train = np.array([0, 0, 0, 1])\n",
        "custom_weights = np.array([0.2, 0.4, 0.6])  # Customized weights\n",
        "custom_bias = -0.5  # Customized bias\n",
        "\n",
        "# Create Perceptron object with custom weights and bias\n",
        "p = Perceptron(weights=custom_weights, bias=custom_bias)\n",
        "\n",
        "# Train the perceptron\n",
        "p.train(X_train, y_train, epochs=100, learning_rate=0.1)\n",
        "\n",
        "# Test prediction\n",
        "test_input = np.array([0, 1, 1])\n",
        "print(\"Prediction:\", p.predict(test_input))  # Output: 0\n",
        "\n",
        "# Evaluate accuracy\n",
        "X_test = np.array([[0, 0, 1], [0, 1, 1], [1, 0, 1], [1, 1, 1]])\n",
        "y_test = np.array([0, 0, 0, 1])\n",
        "\n",
        "# Predict on test data\n",
        "pred = np.array([p.predict(x) for x in X_test])\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = np.mean(pred == y_test) * 100\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7C9wJ5KLvmA",
        "outputId": "d5931f64-a615-410b-9071-6713a747e694"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: 0\n",
            "Accuracy: 100.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.image restyling"
      ],
      "metadata": {
        "id": "mo9bAnO0MoNW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Hebbian Learning Rule\n",
        "def hebbian_learning_rule(input_pattern, weight_matrix):\n",
        "    return weight_matrix + np.outer(input_pattern, input_pattern)\n",
        "\n",
        "# Perceptron Learning Rule\n",
        "def perceptron_learning_rule(input_pattern, target, weight_vector, learning_rate):\n",
        "    prediction = np.dot(weight_vector, input_pattern)\n",
        "    error = target - prediction\n",
        "    return weight_vector + learning_rate * error * input_pattern\n",
        "\n",
        "# Delta Learning Rule\n",
        "def delta_learning_rule(input_pattern, target, weight_matrix, learning_rate):\n",
        "    prediction = np.dot(weight_matrix, input_pattern)\n",
        "    error = target - prediction\n",
        "    return weight_matrix + learning_rate * np.outer(error, input_pattern)\n",
        "\n",
        "# Correlation Learning Rule\n",
        "def correlation_learning_rule(input_pattern, weight_matrix):\n",
        "    return weight_matrix + np.outer(input_pattern, input_pattern)\n",
        "\n",
        "# Out Star Learning Rule\n",
        "def out_star_learning_rule(input_pattern, weight_matrix, learning_rate):\n",
        "    return weight_matrix + learning_rate * np.outer(input_pattern, input_pattern)\n",
        "\n",
        "input_size = 3\n",
        "\n",
        "# Initialize weights with random values\n",
        "hebbian_weights = np.random.rand(input_size, input_size)\n",
        "perceptron_weights = np.random.rand(input_size)\n",
        "delta_weights = np.random.rand(input_size, input_size)\n",
        "correlation_weights = np.random.rand(input_size, input_size)\n",
        "out_star_weights = np.random.rand(input_size, input_size)\n",
        "\n",
        "# Example input pattern and target\n",
        "input_pattern = np.array([1, -1, 0])\n",
        "target = np.array([1, 0, -1])\n",
        "learning_rate = 0.1\n",
        "\n",
        "# Update weights using different learning rules\n",
        "hebbian_weights = hebbian_learning_rule(input_pattern, hebbian_weights)\n",
        "perceptron_weights = perceptron_learning_rule(input_pattern, target[0], perceptron_weights, learning_rate)\n",
        "delta_weights = delta_learning_rule(input_pattern, target, delta_weights, learning_rate)\n",
        "correlation_weights = correlation_learning_rule(input_pattern, correlation_weights)\n",
        "out_star_weights = out_star_learning_rule(input_pattern, out_star_weights, learning_rate)\n",
        "\n",
        "# Print updated weights\n",
        "print(\"Updated Hebbian Weights:\\n\", hebbian_weights)\n",
        "print(\"\\nUpdated Perceptron Weights:\\n\", perceptron_weights)\n",
        "print(\"\\nUpdated Delta Weights:\\n\", delta_weights)\n",
        "print(\"\\nUpdated Correlation Weights:\\n\", correlation_weights)\n",
        "print(\"\\nUpdated Out Star Weights:\\n\", out_star_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2N41YWXM4mM",
        "outputId": "de236a75-0db0-495b-e7f2-305953bbae6d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated Hebbian Weights:\n",
            " [[ 1.19604042 -0.40891704  0.51688801]\n",
            " [-0.80500576  1.11132618  0.42139586]\n",
            " [ 0.34666524  0.71196842  0.88225788]]\n",
            "\n",
            "Updated Perceptron Weights:\n",
            " [0.88956885 0.09648911 0.78743353]\n",
            "\n",
            "Updated Delta Weights:\n",
            " [[0.61692365 0.13341881 0.43267892]\n",
            " [0.78775214 0.68036325 0.23208412]\n",
            " [0.88048664 1.00475197 0.76343771]]\n",
            "\n",
            "Updated Correlation Weights:\n",
            " [[ 1.7201964  -0.5015583   0.42116667]\n",
            " [-0.9051306   1.11596023  0.20666706]\n",
            " [ 0.33574168  0.49753173  0.25789678]]\n",
            "\n",
            "Updated Out Star Weights:\n",
            " [[0.55186485 0.32337899 0.89419064]\n",
            " [0.52832023 0.80941757 0.30239167]\n",
            " [0.98289565 0.26689553 0.12987891]]\n"
          ]
        }
      ]
    }
  ]
}